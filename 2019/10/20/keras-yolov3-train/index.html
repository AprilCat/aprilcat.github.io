<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>keras-yolov3训练自己的数据 | VoidSoul's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.4.0/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-148031274-1','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">keras-yolov3训练自己的数据</h1><a id="logo" href="/.">VoidSoul's Blog</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="https://github.com/AprilCat/"><i class="fa fa-github"> GitHub</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">keras-yolov3训练自己的数据</h1><div class="post-meta">Oct 20, 2019</div><a class="disqus-comment-count" data-disqus-identifier="2019/10/20/keras-yolov3-train/" href="/2019/10/20/keras-yolov3-train/#disqus_thread"></a><div class="post-content"><h2 id="keras-yolov3基本使用"><a href="#keras-yolov3基本使用" class="headerlink" title="keras-yolov3基本使用"></a>keras-yolov3基本使用</h2><p><a href="https://github.com/qqwweee/keras-yolo3" target="_blank" rel="noopener">keras-yolov3</a>是yolov3算法的keras实现，之所以找keras实现是因为tensorflow-gpu经过个人测试是相对比较完整的支持cuda的。opencv 4.1.1 如今的dnn模块还不能通过cuda进行加速，opencv官方现在仍在努力。基本使用方法这边不再表述，项目的README.md文件中已经描述的很清楚了。使用过程中碰到的一个要注意的地方就是不要安装当前最新的tensorflow-gpu 2.0，实测1.15rc3是正常的，主要原因是2.0里没有了get_session方法，运行会报错。用gtx1050时的推理速度是6~7fps，比用cpu的0.5fps快很多了。接下来开始训练自己的检测分类和数据。</p>
<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><h3 id="视频截图"><a href="#视频截图" class="headerlink" title="视频截图"></a>视频截图</h3><p>数据源是一堆视频，但是我们需要截成jpg图片才能使用。发现<a href="https://github.com/AlexeyAB/Yolo_mark" target="_blank" rel="noopener">yolo_mark</a>工具除了可以标记数据，也可以从视频中批量截取jpg照片。通过yolo mark这个工具标记的数据格式跟keras-yolov3所需的数据格式不同，但是yolo_mark将视频自动截图的功能挺好用的。yolo mark项目依赖opencv2 或 opencv3，使用过程中实测确实不能用opencv 4。</p>
<h3 id="准备VOC文件夹框架"><a href="#准备VOC文件夹框架" class="headerlink" title="准备VOC文件夹框架"></a>准备VOC文件夹框架</h3><p>想要训练自己的数据，keras-yolov3作者建议用voc_annotation.py这个工具来标记数据，那要用到这个工具的话那我们就需要把数据整理成VOC数据集的样式（VOC数据格式也是ImageNet使用的格式）。先在keras-yolov3根目录下新建一个VOC数据集的文件夹框架（里面不能有其他文件，只有文件夹），文件夹组织如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">VOCdevkit</span><br><span class="line">       └VOC2007</span><br><span class="line">              ├Annotations</span><br><span class="line">              ├ImageSets</span><br><span class="line">              │     ├Layout</span><br><span class="line">              │     ├Main</span><br><span class="line">              │     └Segmentation</span><br><span class="line">              ├JPEGImages</span><br><span class="line">              └labels</span><br></pre></td></tr></table></figure></p>
<h3 id="使用labelImg标记数据"><a href="#使用labelImg标记数据" class="headerlink" title="使用labelImg标记数据"></a>使用labelImg标记数据</h3><p>使用<a href="https://github.com/tzutalin/labelImg" target="_blank" rel="noopener">labelImg</a>工具进行数据标记，使用方法项目readme文件有说明。可以把图片数据放在lanbelImg/data/img目录下，想要预先分拣出的分类写到labelImg/data/predefined_classes.txt文件中。使用如下指令运行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python labelImg.py data/img data/predefined_classes.txt</span><br></pre></td></tr></table></figure></p>
<p>标记完成的jpg放到VOC的JPEGImages文件夹里，data/annotation下的xml文件放到VOC的Annotations文件夹里。<br>返回到keras-yolov3的目录下，切到VOC2007目录下新建一个python脚本文件，用以生成VOC2007/ImageSets/Main目录下的四个txt文件：train.txt, val.txt, trainval.txt, test.txt，脚本内容如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">trainval_percent = <span class="number">0.1</span></span><br><span class="line">train_percent = <span class="number">0.9</span></span><br><span class="line">xmlfilepath = <span class="string">'Annotations'</span></span><br><span class="line">txtsavepath = <span class="string">'ImageSets/Main'</span></span><br><span class="line">total_xml = os.listdir(xmlfilepath)</span><br><span class="line"></span><br><span class="line">num = len(total_xml)</span><br><span class="line">list = range(num)</span><br><span class="line">tv = int(num * trainval_percent)</span><br><span class="line">tr = int(tv * train_percent)</span><br><span class="line">trainval = random.sample(list, tv)</span><br><span class="line">train = random.sample(trainval, tr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(txtsavepath):</span><br><span class="line">    print(<span class="string">'not exist...&#123;&#125;'</span>.format(txtsavepath))</span><br><span class="line">    os.makedirs(txtsavepath)</span><br><span class="line"></span><br><span class="line">ftrainval = open(<span class="string">'ImageSets/Main/trainval.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">ftest = open(<span class="string">'ImageSets/Main/test.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">ftrain = open(<span class="string">'ImageSets/Main/train.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line">fval = open(<span class="string">'ImageSets/Main/val.txt'</span>, <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list:</span><br><span class="line">    name = total_xml[i][:<span class="number">-4</span>] + <span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">if</span> i <span class="keyword">in</span> trainval:</span><br><span class="line">        ftrainval.write(name)</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">in</span> train:</span><br><span class="line">            ftest.write(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fval.write(name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ftrain.write(name)</span><br><span class="line"></span><br><span class="line">ftrainval.close()</span><br><span class="line">ftrain.close()</span><br><span class="line">fval.close()</span><br><span class="line">ftest.close()</span><br></pre></td></tr></table></figure></p>
<p>保存后运行。接着修改keras-yolov3目录下的voc_annotation.py中的classes，设定为自己所需的分类后，保存，运行。会发现主目录下多了3个文件：2007_text.txt，2007_train.txt，2007_val.txt。</p>
<h3 id="准备预训练模型"><a href="#准备预训练模型" class="headerlink" title="准备预训练模型"></a>准备预训练模型</h3><p>下载darknet的<a href="https://pjreddie.com/media/files/darknet53.conv.74" target="_blank" rel="noopener">预训练模型</a>并且重命名为darknet53.weights。通过以下指令将其转换成keras需要的h5格式<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python convert.py -w darknet53.cfg darknet53.weights model_data/yolo_weights.h5</span><br></pre></td></tr></table></figure></p>
<p>运行中如果出现requires 某个库的错误那就安装一下然后重新运行。检查yolo_weights.h5文件是否有生成。</p>
<h3 id="修改classes文件"><a href="#修改classes文件" class="headerlink" title="修改classes文件"></a>修改classes文件</h3><p>修改model_data/voc_classes.txt，将内容改成自己所需要的类别</p>
<h3 id="修改anchor文件"><a href="#修改anchor文件" class="headerlink" title="修改anchor文件"></a>修改anchor文件</h3><p>anchor设置好坏影响训练和推理的结果，通过kmeans.py脚本可以得到我们训练集所对应的anchor。将得到的anchors值填入model_data/yolo_anchors.txt中。</p>
<h3 id="修改yolov3-cfg文件"><a href="#修改yolov3-cfg文件" class="headerlink" title="修改yolov3.cfg文件"></a>修改yolov3.cfg文件</h3><p>参照这篇文章进行修改 <a href="https://blog.csdn.net/ll_master/article/details/81487844" target="_blank" rel="noopener">yolo3 配置文件yolo3_voc.cfg参数学习</a>。</p>
<ul>
<li>首先前面几行将testing相关的设置注释掉，将training相关的设置取消注释。</li>
<li>查找yolo，总共会发现3个地方。每个地方都有4个变量要修改：filters，classes和random。</li>
<li><ol>
<li>classes就是我们需要推理的分类数量，我这里是2</li>
</ol>
</li>
<li><ol start="2">
<li>filters = 3 * (5 + len(classes))，我这里就是21</li>
</ol>
</li>
<li><ol start="3">
<li>如果显存比较小random要从1改为0 </li>
</ol>
</li>
<li><ol start="4">
<li>anchors值改为上述kmeans.py求出的anchor值。<h2 id="进行训练"><a href="#进行训练" class="headerlink" title="进行训练"></a>进行训练</h2>直接运行python train.py。<h3 id="训练时的一些错误"><a href="#训练时的一些错误" class="headerlink" title="训练时的一些错误"></a>训练时的一些错误</h3>如果提示如下错误：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AttributeError: module <span class="string">'keras.backend'</span> has no attribute <span class="string">'control_flow_ops'</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<p>则需要卸载掉当前版本的keras，然后安装keras 2.1.5。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall keras</span><br><span class="line">pip install keras==2.1.5</span><br></pre></td></tr></table></figure></p>
<p>如果提示错误是下面这个样子的，这个一般在运行中途时候出现：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions <span class="keyword">for</span> current allocation info.</span><br></pre></td></tr></table></figure></p>
<p>或者什么类似于资源一类的字眼出现，那一般是gpu的显存不足，在train.py中将batch_size修改小，默认是32，可以改成16或者8或者4，但是改小会导致模型精度下降。GTX1050改到2了才没有报错，可能后期会将训练转移动云服务器上进行。</p>
<h3 id="训练完成"><a href="#训练完成" class="headerlink" title="训练完成"></a>训练完成</h3><p>寻找一个trained_weights_final.h5文件，将该文件拷贝到model_data目录下，并且改名为yolo.h5，（原来的yolo.h5需要做好备份）。</p>
<h3 id="进行推理"><a href="#进行推理" class="headerlink" title="进行推理"></a>进行推理</h3><p>model_data/voc_classes.txt里改为自己的分类，另外yolov3.cfg文件前面的training要换回testing。yolo.py第26行的score可以改低点，如果没改低可能很难检测出来。<br>然后运行如下指令进行推理<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python yolo_video.py --input ../keras/mp4/test.mp4 --classes=model_data/voc_classes.txt</span><br></pre></td></tr></table></figure></p>
<h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>代码分析什么的……emmmm</p>
</div><div class="tags"></div><div class="post-nav"><a class="next" href="/2019/10/19/install-opencv-cuda/">自行编译使能cuda支持的opencv 4.1.1</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://voidsoul.cc/2019/10/20/keras-yolov3-train/';
    this.page.identifier = '2019/10/20/keras-yolov3-train/';
    this.page.title = 'keras-yolov3训练自己的数据';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//voidsoul.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//voidsoul.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://voidsoul.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://voidsoul.cc"/></form></div><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://voidsoul.cc"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/summary/" style="font-size: 15px;">summary</a> <a href="/tags/stm32/" style="font-size: 15px;">stm32</a> <a href="/tags/mysql-database/" style="font-size: 15px;">mysql database</a> <a href="/tags/proxy/" style="font-size: 15px;">proxy</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/10/20/keras-yolov3-train/">keras-yolov3训练自己的数据</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/19/install-opencv-cuda/">自行编译使能cuda支持的opencv 4.1.1</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/03/ffmpeg-vaapi/">在up squared上让ffmpeg支持硬件编解码</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/29/cJSON-usage/">cJSON用法小结</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/16/lantern-proxy/">lantern 开启代理供局域网内其他电脑使用</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/Hi3516CV300-uboot/">Hi3516CV300 uboot 固化启动参数</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/How-to-embedded-GA/">如何在Hexo中嵌入Google Analytics</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/14/Hi3516-MD/">Hi3516CV300 移动侦测实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/01/2018.summary/">2018 个人总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/01/hadoop-single/">hadoop 的安装与分布式模式配置</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//voidsoul.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://yemi.me/" title="yemi" target="_blank">yemi</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">VoidSoul's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>